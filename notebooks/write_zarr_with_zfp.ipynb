{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster, SLURMCluster\n",
    "from distributed import Client\n",
    "import xarray as xr\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' create a cluster object to specify PBS queue requirement, project should be set as your project account '''\n",
    "''' processes means number of core will be used. I set processes = 1 to process large files, you can set to \n",
    "    at most 10 to process small files '''\n",
    "cluster=PBSCluster(\n",
    "            cores=36,\n",
    "            memory='109GB',\n",
    "            processes=1,\n",
    "            local_directory='$TMPDIR',\n",
    "            interface='ib0',\n",
    "            queue='regular',\n",
    "            walltime='00:30:00',\n",
    "            project='*****',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f981190093047deb12538c5c913e3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>PBSCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' for large file, you can set manual scaling workers = 2 or more '''\n",
    "''' workers here mean number of nodes will be used '''\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.148.10.15:40993</li>\n",
       "  <li><b>Dashboard: </b><a href='https://jupyterhub.ucar.edu/ch/user/haiyingx/proxy/8787/status' target='_blank'>https://jupyterhub.ucar.edu/ch/user/haiyingx/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>72</li>\n",
       "  <li><b>Memory: </b>134.16 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.148.10.15:40993' processes=2 threads=72, memory=134.16 GB>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client=Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' open the Falko dataset with chunk setting as nCells = 4194305 '''\n",
    "filename='/glade/scratch/fjudt/projects/ongoing/dyamond/dyamond_1/runs/3.75km/history.2016-08-01_00.00.00.nc'\n",
    "chunk_dict = {'nCells': 4194305}\n",
    "ds=xr.open_dataset(filename,chunks=chunk_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_zarr(ds, output_filename, output_dir, chunk_dict, error_bound=None):\n",
    "\n",
    "    import zarr\n",
    "    from numcodecs.zfpy import _zfpy, ZFPY\n",
    "    \n",
    "    ''' manually set chunk size for zarr file '''\n",
    "    ''' you should change to a chunk size that meet your specific dimensions'''\n",
    "    ds1 = ds.chunk(chunks=chunk_dict)\n",
    "    if error_bound is not None:\n",
    "        ''' create a compressor with compressor zfp in mode a, absolute tolerance should be equal to error_bound '''\n",
    "        compressor = ZFPY(mode=_zfpy.mode_fixed_accuracy,tolerance=error_bound)\n",
    "        \n",
    "        for k, v in ds1.items():\n",
    "            \n",
    "            ''' check for time variant variables to be compressed '''\n",
    "            if ds1[k].dtype=='float32' and len(ds1[k].dims) >= 2:\n",
    "                ''' set the variable k to the compressor zfp'''\n",
    "                ds1[k].encoding['compressor']=compressor\n",
    "    else:\n",
    "        ''' default compressor is zlib at level 5 '''\n",
    "        error_bound = 'zlib.5'\n",
    "    ''' create a zarr file name '''\n",
    "    filename=output_dir+'/'+output_filename+('.')+str(error_bound)+'.zarr'\n",
    "\n",
    "    ''' write out to zarr format '''\n",
    "    ds1.to_zarr(filename, mode='w', consolidated=True)  \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' read in compressed zarr file and write to netcdf file with zlib=5 '''\n",
    "\n",
    "def write_to_netcdf(zarr_name):\n",
    "    \n",
    "    ds=xr.open_zarr(zarr_name)\n",
    "\n",
    "    comp = dict(zlib=True, complevel=5)\n",
    "    encoding = {var: comp for var in ds.data_vars if ds[var].dtype=='float32' and len(ds[var].dims)>=2}\n",
    "    output_filename=zarr_name[:-5]+'.nc'\n",
    "    ds.to_netcdf(output_filename,encoding=encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.18 s, sys: 561 ms, total: 3.74 s\n",
      "Wall time: 2min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/glade/scratch/haiyingx/history.2016-08-01_00.00.00.0.1.zarr'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time  \n",
    "from os.path import basename\n",
    "\n",
    "output_dir='/glade/scratch/haiyingx'\n",
    "error_bound = 0.1\n",
    "''' if passing argument error_bound, zfp compressor will be used, if not, zlib level 1 will be used '''\n",
    "zarr_name=convert_zarr(ds, basename(filename)[:-3], output_dir, chunk_dict, error_bound)\n",
    "zarr_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This procedure is very slow for this input file'''\n",
    "#write_to_netcdf(zarr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 587 ms, sys: 86.2 ms, total: 673 ms\n",
      "Wall time: 30.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "''' open the compressed data file to validate '''\n",
    "ds2 = xr.open_zarr(zarr_name)\n",
    "''' read variable w data '''\n",
    "decomp_arr = ds2.w.data\n",
    "orig_arr = ds.w.data\n",
    "''' compare if decomp_arr and orig_arr are element-wise equal within a tolerance '''\n",
    "''' I set atol=0.01 to check on compressed to 0.1 data, we will get false '''\n",
    "''' if we set atol=0.1, we will get back true '''\n",
    "validate = da.allclose(decomp_arr,orig_arr,rtol=0.0, atol=0.01)\n",
    "''' if two arrays are equal, allclose will return true '''\n",
    "validate.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-pangeo-bench]",
   "language": "python",
   "name": "conda-env-miniconda3-pangeo-bench-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
